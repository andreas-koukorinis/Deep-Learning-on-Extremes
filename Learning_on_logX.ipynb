{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning of the Extreme Value Index\n",
    "\n",
    "Estimating the extreme value index, which describes the tail behavior of Pareto-type distributions, is a complex task and estimators usually depend on the choice of a threshold, above which the data can be used for statistical inference on extreme events. <br>\n",
    "The question I want to discuss here is: Can I train a network on random samples to determine the extreme value index without the selection of a threshod?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stat\n",
    "import random\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following the training data is generated. For the network to learn well it is very important to obtain training samples, which represent a broad class of distributions. <br>\n",
    "Since I am working on samples from heavy-tailed distributions, which can include extremely high values, I can not use the samples directly for training the network. Instead of the raw obervations I look at their logarithm. This trick leads to a more reasonable range of observed values and is also a natural thing to do in extreme value statistics, as it leads to an exponential approximation of the peak-over-threshold approach instead of a pareto approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=500\n",
    "M=5000\n",
    "\n",
    "train_data=np.zeros((3*M,N))\n",
    "labels=np.zeros(3*M)\n",
    "\n",
    "for i in range(M):\n",
    "    degree=np.random.randint(1,12)\n",
    "    X=np.random.standard_t(df=degree, size=N)\n",
    "    train_data[i,]=np.log(abs(X))\n",
    "    labels[i]=1./degree\n",
    "    \n",
    "for i in range(M):\n",
    "    gamma=np.random.uniform(low=0, high=3)\n",
    "    X=stat.invweibull.rvs(c=1/gamma, size=N)\n",
    "    train_data[M+i,]=np.log(X)\n",
    "    labels[M+i]=gamma\n",
    "\n",
    "for i in range(M):\n",
    "    gamma=np.random.uniform(low=0, high=3)\n",
    "    X=np.random.uniform(size=N)\n",
    "    X=np.power((1/(1-X) -1), gamma)\n",
    "    train_data[2*M+i,]=np.log(X)\n",
    "    labels[2*M+i]=gamma\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The network architecture\n",
    "\n",
    "In the case considered here, where the input does not contain structral properties, the only useful network is a fully connnected sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelH=tf.keras.models.Sequential()\n",
    "modelH.add(tf.keras.layers.Dense(N, input_shape=(N,) , activation='relu', use_bias=True))\n",
    "modelH.add(tf.keras.layers.Dense(2*N, activation='relu', use_bias=True ))\n",
    "modelH.add(tf.keras.layers.Dense(N, activation='relu', use_bias=True ))\n",
    "modelH.add(tf.keras.layers.Dense(1, use_bias=True))\n",
    "\n",
    "modelH.compile(optimizer='adam', loss='mse', metrics=[\"mae\"])\n",
    "#RMSprop each model varies a lot\n",
    "#SGD leads  to nan\n",
    "#with Adam the loss can increase by times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a short check, if the initialized function values are not too far away from the true labels. Starting values that are by orders of magnitude higher or smaller than the true label values would lead too a very slow training speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16088665],\n",
       "       [-0.93340528],\n",
       "       [-0.55824888],\n",
       "       ..., \n",
       "       [-0.48357075],\n",
       "       [ 0.16883616],\n",
       "       [-0.02772872]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelH.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=np.zeros((3*M,N))\n",
    "test_labels=np.zeros(3*M)\n",
    "\n",
    "for i in range(M):\n",
    "    degree=np.random.randint(1,12)\n",
    "    X=np.random.standard_t(df=degree, size=N)\n",
    "    test_data[i,]=np.log(abs(X))\n",
    "    test_labels[i]=1./degree\n",
    "    \n",
    "for i in range(M):\n",
    "    gamma=np.random.uniform(low=0, high=3)\n",
    "    X=stat.invweibull.rvs(c=1/gamma, size=N)\n",
    "    test_data[M+i,]=np.log(X)\n",
    "    test_labels[M+i]=gamma\n",
    "\n",
    "for i in range(M):\n",
    "    gamma=np.random.uniform(low=0, high=3)\n",
    "    X=np.random.uniform(size=N)\n",
    "    X=np.power((1/(1-X) -1), gamma)\n",
    "    test_data[2*M+i,]=np.log(X)\n",
    "    test_labels[2*M+i]=gamma\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 15000 samples\n",
      "Epoch 1/50\n",
      "15000/15000 [==============================] - 5s 346us/step - loss: 0.5350 - mean_absolute_error: 0.2062 - val_loss: 0.0182 - val_mean_absolute_error: 0.0937\n",
      "Epoch 2/50\n",
      "15000/15000 [==============================] - 5s 323us/step - loss: 0.0124 - mean_absolute_error: 0.0796 - val_loss: 0.0154 - val_mean_absolute_error: 0.0858\n",
      "Epoch 3/50\n",
      "15000/15000 [==============================] - 5s 319us/step - loss: 0.0081 - mean_absolute_error: 0.0663 - val_loss: 0.0147 - val_mean_absolute_error: 0.0836\n",
      "Epoch 4/50\n",
      "15000/15000 [==============================] - 5s 325us/step - loss: 0.0058 - mean_absolute_error: 0.0572 - val_loss: 0.0156 - val_mean_absolute_error: 0.0857\n",
      "Epoch 5/50\n",
      "15000/15000 [==============================] - 5s 319us/step - loss: 0.0048 - mean_absolute_error: 0.0521 - val_loss: 0.0135 - val_mean_absolute_error: 0.0813\n",
      "Epoch 6/50\n",
      "15000/15000 [==============================] - 5s 319us/step - loss: 0.0050 - mean_absolute_error: 0.0525 - val_loss: 0.0139 - val_mean_absolute_error: 0.0812\n",
      "Epoch 7/50\n",
      "15000/15000 [==============================] - 5s 318us/step - loss: 0.0054 - mean_absolute_error: 0.0534 - val_loss: 0.0129 - val_mean_absolute_error: 0.0793\n",
      "Epoch 8/50\n",
      "15000/15000 [==============================] - 5s 324us/step - loss: 0.0068 - mean_absolute_error: 0.0586 - val_loss: 0.0133 - val_mean_absolute_error: 0.0799\n",
      "Epoch 9/50\n",
      "15000/15000 [==============================] - 5s 319us/step - loss: 0.0070 - mean_absolute_error: 0.0594 - val_loss: 0.0142 - val_mean_absolute_error: 0.0828\n",
      "Epoch 10/50\n",
      "15000/15000 [==============================] - 5s 321us/step - loss: 0.0065 - mean_absolute_error: 0.0567 - val_loss: 0.0126 - val_mean_absolute_error: 0.0783\n",
      "Epoch 11/50\n",
      "15000/15000 [==============================] - 5s 319us/step - loss: 0.0057 - mean_absolute_error: 0.0536 - val_loss: 0.0121 - val_mean_absolute_error: 0.0762\n",
      "Epoch 12/50\n",
      "15000/15000 [==============================] - 5s 314us/step - loss: 0.0063 - mean_absolute_error: 0.0556 - val_loss: 0.0149 - val_mean_absolute_error: 0.0839\n",
      "Epoch 13/50\n",
      "15000/15000 [==============================] - 5s 320us/step - loss: 0.0082 - mean_absolute_error: 0.0625 - val_loss: 0.0128 - val_mean_absolute_error: 0.0790\n",
      "Epoch 14/50\n",
      "15000/15000 [==============================] - 5s 313us/step - loss: 0.0127 - mean_absolute_error: 0.0756 - val_loss: 0.0168 - val_mean_absolute_error: 0.0898\n",
      "Epoch 15/50\n",
      "15000/15000 [==============================] - 5s 318us/step - loss: 0.0134 - mean_absolute_error: 0.0766 - val_loss: 0.0162 - val_mean_absolute_error: 0.0891\n",
      "Epoch 16/50\n",
      "15000/15000 [==============================] - 5s 316us/step - loss: 0.0144 - mean_absolute_error: 0.0794 - val_loss: 0.0154 - val_mean_absolute_error: 0.0857\n",
      "Epoch 17/50\n",
      "15000/15000 [==============================] - 5s 320us/step - loss: 0.0144 - mean_absolute_error: 0.0781 - val_loss: 0.0222 - val_mean_absolute_error: 0.1007\n",
      "Epoch 18/50\n",
      "15000/15000 [==============================] - 5s 315us/step - loss: 0.0154 - mean_absolute_error: 0.0816 - val_loss: 0.0163 - val_mean_absolute_error: 0.0897\n",
      "Epoch 19/50\n",
      "15000/15000 [==============================] - 5s 317us/step - loss: 0.0159 - mean_absolute_error: 0.0819 - val_loss: 0.0185 - val_mean_absolute_error: 0.0936\n",
      "Epoch 20/50\n",
      "15000/15000 [==============================] - 5s 324us/step - loss: 0.0119 - mean_absolute_error: 0.0713 - val_loss: 0.0265 - val_mean_absolute_error: 0.1089\n",
      "Epoch 21/50\n",
      "15000/15000 [==============================] - 5s 319us/step - loss: 0.0099 - mean_absolute_error: 0.0646 - val_loss: 0.0186 - val_mean_absolute_error: 0.0930\n",
      "Epoch 22/50\n",
      "15000/15000 [==============================] - 5s 316us/step - loss: 0.0100 - mean_absolute_error: 0.0641 - val_loss: 0.0183 - val_mean_absolute_error: 0.0939\n",
      "Epoch 23/50\n",
      "15000/15000 [==============================] - 5s 315us/step - loss: 0.0102 - mean_absolute_error: 0.0648 - val_loss: 0.0184 - val_mean_absolute_error: 0.0918\n",
      "Epoch 24/50\n",
      "15000/15000 [==============================] - 5s 315us/step - loss: 0.0097 - mean_absolute_error: 0.0627 - val_loss: 0.0153 - val_mean_absolute_error: 0.0856\n",
      "Epoch 25/50\n",
      "15000/15000 [==============================] - 5s 314us/step - loss: 0.0090 - mean_absolute_error: 0.0607 - val_loss: 0.0155 - val_mean_absolute_error: 0.0853\n",
      "Epoch 26/50\n",
      "15000/15000 [==============================] - 5s 365us/step - loss: 0.0086 - mean_absolute_error: 0.0594 - val_loss: 0.0177 - val_mean_absolute_error: 0.0920\n",
      "Epoch 27/50\n",
      "15000/15000 [==============================] - 5s 317us/step - loss: 0.0087 - mean_absolute_error: 0.0595 - val_loss: 0.0192 - val_mean_absolute_error: 0.0946\n",
      "Epoch 28/50\n",
      "15000/15000 [==============================] - 5s 316us/step - loss: 0.0083 - mean_absolute_error: 0.0572 - val_loss: 0.0169 - val_mean_absolute_error: 0.0866\n",
      "Epoch 29/50\n",
      "15000/15000 [==============================] - 5s 316us/step - loss: 0.0072 - mean_absolute_error: 0.0538 - val_loss: 0.0186 - val_mean_absolute_error: 0.0913\n",
      "Epoch 30/50\n",
      "15000/15000 [==============================] - 5s 316us/step - loss: 0.0065 - mean_absolute_error: 0.0523 - val_loss: 0.0192 - val_mean_absolute_error: 0.0915\n",
      "Epoch 31/50\n",
      "15000/15000 [==============================] - 5s 312us/step - loss: 0.0067 - mean_absolute_error: 0.0521 - val_loss: 0.0192 - val_mean_absolute_error: 0.0920\n",
      "Epoch 32/50\n",
      "15000/15000 [==============================] - 5s 317us/step - loss: 0.0064 - mean_absolute_error: 0.0501 - val_loss: 0.0174 - val_mean_absolute_error: 0.0922\n",
      "Epoch 33/50\n",
      "15000/15000 [==============================] - 5s 313us/step - loss: 0.0067 - mean_absolute_error: 0.0523 - val_loss: 0.0224 - val_mean_absolute_error: 0.0978\n",
      "Epoch 34/50\n",
      "15000/15000 [==============================] - 5s 316us/step - loss: 0.0059 - mean_absolute_error: 0.0489 - val_loss: 0.0220 - val_mean_absolute_error: 0.0975\n",
      "Epoch 35/50\n",
      "15000/15000 [==============================] - 5s 314us/step - loss: 0.0059 - mean_absolute_error: 0.0490 - val_loss: 0.0170 - val_mean_absolute_error: 0.0878\n",
      "Epoch 36/50\n",
      "15000/15000 [==============================] - 5s 317us/step - loss: 0.0056 - mean_absolute_error: 0.0475 - val_loss: 0.0215 - val_mean_absolute_error: 0.0958\n",
      "Epoch 37/50\n",
      "15000/15000 [==============================] - 5s 343us/step - loss: 0.0050 - mean_absolute_error: 0.0457 - val_loss: 0.0225 - val_mean_absolute_error: 0.0979\n",
      "Epoch 38/50\n",
      "15000/15000 [==============================] - 5s 339us/step - loss: 0.0049 - mean_absolute_error: 0.0445 - val_loss: 0.0213 - val_mean_absolute_error: 0.0953\n",
      "Epoch 39/50\n",
      "15000/15000 [==============================] - 5s 357us/step - loss: 0.0051 - mean_absolute_error: 0.0458 - val_loss: 0.0207 - val_mean_absolute_error: 0.0957\n",
      "Epoch 40/50\n",
      "15000/15000 [==============================] - 5s 318us/step - loss: 0.0050 - mean_absolute_error: 0.0455 - val_loss: 0.0230 - val_mean_absolute_error: 0.0982\n",
      "Epoch 41/50\n",
      "15000/15000 [==============================] - 6s 392us/step - loss: 0.0045 - mean_absolute_error: 0.0431 - val_loss: 0.0292 - val_mean_absolute_error: 0.1090\n",
      "Epoch 42/50\n",
      "15000/15000 [==============================] - 5s 366us/step - loss: 0.0040 - mean_absolute_error: 0.0405 - val_loss: 0.0210 - val_mean_absolute_error: 0.0959\n",
      "Epoch 43/50\n",
      "15000/15000 [==============================] - 6s 374us/step - loss: 0.0040 - mean_absolute_error: 0.0409 - val_loss: 0.0257 - val_mean_absolute_error: 0.1030\n",
      "Epoch 44/50\n",
      "15000/15000 [==============================] - 6s 417us/step - loss: 0.0042 - mean_absolute_error: 0.0412 - val_loss: 0.0259 - val_mean_absolute_error: 0.1043\n",
      "Epoch 45/50\n",
      "15000/15000 [==============================] - 6s 374us/step - loss: 0.0043 - mean_absolute_error: 0.0425 - val_loss: 0.0211 - val_mean_absolute_error: 0.0954\n",
      "Epoch 46/50\n",
      "15000/15000 [==============================] - 5s 328us/step - loss: 0.0041 - mean_absolute_error: 0.0403 - val_loss: 0.0241 - val_mean_absolute_error: 0.1002\n",
      "Epoch 47/50\n",
      "15000/15000 [==============================] - 5s 316us/step - loss: 0.0039 - mean_absolute_error: 0.0399 - val_loss: 0.0260 - val_mean_absolute_error: 0.1033\n",
      "Epoch 48/50\n",
      "15000/15000 [==============================] - 5s 318us/step - loss: 0.0033 - mean_absolute_error: 0.0363 - val_loss: 0.0257 - val_mean_absolute_error: 0.1037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "15000/15000 [==============================] - 5s 317us/step - loss: 0.0032 - mean_absolute_error: 0.0358 - val_loss: 0.0239 - val_mean_absolute_error: 0.1020\n",
      "Epoch 50/50\n",
      "15000/15000 [==============================] - 5s 320us/step - loss: 0.0032 - mean_absolute_error: 0.0355 - val_loss: 0.0241 - val_mean_absolute_error: 0.1006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0fe37745c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelH.fit(train_data, labels, epochs=50, validation_data=(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The comparison for fixed sample size\n",
    "\n",
    "Now I want to test the networks performance on samples from a Frechet(2) and a Cauchy distribution, where the true extreme value index is 1/2 and 1 respectively. Both distibutions are commonly usd examples in extreme value analsis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=500\n",
    "## Frechet(2)\n",
    "test_dataFl=np.zeros((M,N))\n",
    "test_dataF=np.zeros((M,N))\n",
    "test_labelsF=np.zeros(M)\n",
    "    \n",
    "for i in range(M):\n",
    "    gamma=1/2\n",
    "    X=stat.invweibull.rvs(c=1/gamma, size=N)\n",
    "    test_dataFl[i,]=np.log(X)\n",
    "    test_dataF[i,]=X\n",
    "    test_labelsF[i]=gamma\n",
    "    \n",
    "    \n",
    "## Cauchy\n",
    "test_dataCl=np.zeros((M,N))\n",
    "test_dataC=np.zeros((M,N))\n",
    "test_labelsC=np.zeros(M)\n",
    "\n",
    "for i in range(M):\n",
    "    X=np.random.standard_cauchy(size=N)\n",
    "    test_dataCl[i,]=np.log(abs(X))\n",
    "    test_dataC[i,]=X\n",
    "    test_labelsC[i]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to compare it to a more \"traditional\" statistical procedure and therefore I implemented the method K_star, which I developed for threshold selection and adaptive estimation of the extreme value index using the Hill estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hill(X,k):\n",
    "    N=len(X)\n",
    "    X=np.sort(X)\n",
    "    temp=np.log(X[range(N-k-1,N)])-np.log(X[N-k-1])\n",
    "    return(np.sum(temp)/(k+1))\n",
    "\n",
    "def de_Vries(X,k):\n",
    "    N=len(X)\n",
    "    X=np.sort(X)\n",
    "    temp=np.log(X[range(N-k-1,N)])-np.log(X[N-k-1])\n",
    "    temp2=np.power(temp,2)\n",
    "    return(np.sum(temp2)/(2*np.sum(temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_star(X):\n",
    "    n_p=sum(1 for i in range(len(X)) if X[i]>0)\n",
    "    K=range(4,n_p)\n",
    "    H=np.zeros(len(K))\n",
    "    V=np.zeros(len(K))\n",
    "    Error=np.zeros(len(K))\n",
    "    for k in K:\n",
    "        H[k-K[0]]=Hill(X,k)\n",
    "        V[k-K[0]]=de_Vries(X,k)\n",
    "        Hk=H[range(k-K[0]+1)]\n",
    "        Vk=V[range(k-K[0]+1)]\n",
    "        upHk=(np.cumsum(Hk[::-1]) / range(1, len(Hk)+1))[::-1]\n",
    "        Error[k-K[0]]=np.mean(np.power(Hk-Vk-upHk+upHk[0],2))\n",
    "    Stable=np.zeros(len(K))\n",
    "    for k in K:\n",
    "        Stable[k-K[0]]=np.mean(np.power( (Error[k-K[0]]-Error[range(max(0,k-K[0]-2),min(len(K)-1,k-K[0]+2))]) ,2))\n",
    "        \n",
    "    kstar=K[np.argmin(Stable)]\n",
    "    upHk=(np.cumsum(H[kstar-K[0]::-1]) / range(1,kstar-K[0]+2))[::-1]\n",
    "    MSE=np.zeros(len(range(4,kstar+1)))\n",
    "    for k in range(4,kstar+1):\n",
    "        MSE[k-4]=(2*V[kstar-K[0]]-H[kstar-K[0]])**2/k+4*(upHk[k-4]-upHk[0])**2\n",
    "        \n",
    "    return K[np.argmin(MSE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamma_hatF=np.zeros(500)\n",
    "\n",
    "for i in range(500):\n",
    "    X=test_dataF[i,]\n",
    "    k1=K_star(X)\n",
    "    Gamma_hatF[i]=Hill(X,k1)\n",
    "    \n",
    "    \n",
    "Gamma_hatC=np.zeros(500)\n",
    "\n",
    "for i in range(500):\n",
    "    X=test_dataC[i,]\n",
    "    k1=K_star(X)\n",
    "    Gamma_hatC[i]=Hill(X,k1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the performance of the method K_star to the deep neural network (DNN) in terms of the mean square error (MSE) and the mean absolute error (MAE). We obseve that the DNN performs better in both examples. Although our method K_star is maybe not the optimal thing you can do, it performs quite comparable to other methods. Thus, it offers a realistic evaluation of the estimation performance of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_star - Frechet - MSE: 0.00486883484553 , MAE: 0.0534270257877\n",
      "500/500 [==============================] - 0s 61us/step\n",
      "DNN - Frechet - MSE: 0.00137717017718 , MAE: 0.0299174061716\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"K_star - Frechet - MSE:\", np.mean(np.power((Gamma_hatF-test_labelsF),2)),\", MAE:\", np.mean(np.abs((Gamma_hatF-test_labelsF))))\n",
    "EvF=modelH.evaluate(test_dataFl, test_labelsF)\n",
    "print(\"DNN - Frechet - MSE:\", EvF[0], \", MAE:\", EvF[1])\n",
    "\n",
    "plt.hist(Gamma_hatF, bins=20, label=\"K_star\")\n",
    "plt.hist(modelH.predict(test_dataFl), bins=20, label=\"DNN\")\n",
    "legend = plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_star - Cauchy - MSE: 0.0361568715126 , MAE: 0.149241513737\n",
      "500/500 [==============================] - 0s 64us/step\n",
      "DNN - Cauchy - MSE: 0.0125199482366 , MAE: 0.0971328452826\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"K_star - Cauchy - MSE:\", np.mean(np.power((Gamma_hatC-test_labelsC),2)),\", MAE:\", np.mean(np.abs((Gamma_hatC-test_labelsC))))\n",
    "EvC=modelH.evaluate(test_dataCl, test_labelsC)\n",
    "print(\"DNN - Cauchy - MSE:\", EvC[0], \", MAE:\", EvC[1])\n",
    "\n",
    "plt.hist(Gamma_hatC, bins=20, label=\"K_star\")\n",
    "plt.hist(modelH.predict(test_dataCl), bins=20, label=\"DNN\")\n",
    "legend = plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considering different sample sizes\n",
    "\n",
    "A major drawback of such a network is that the architecture determines the number of observations, which can be processed. Thus, you would either train and possibly model an new network for each sample sizes your are confronted with or you rather consider drawing from you data with replacement to obtain samples of the same size. The second approach makes sense, if you have a various samples which do not very drastically. <br>\n",
    "\n",
    "To evaluate this idea the test data gereated in the following has different sample sizes, but in constrast to the K_star method the DNN is applied to resampled versions of size N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=500\n",
    "dif=200\n",
    "## Frechet(2)\n",
    "test_dataFlv=np.zeros((M,N))\n",
    "test_dataFv=np.zeros((M,N+dif))\n",
    "test_labelsFv=np.zeros(M)\n",
    "    \n",
    "for i in range(M):\n",
    "    gamma=1/2\n",
    "    Nr=np.random.randint(N-dif,N+dif)\n",
    "    Xr=stat.invweibull.rvs(c=1/gamma, size=Nr)\n",
    "    if Nr>=N:\n",
    "        X=np.asarray(random.sample(list(Xr),N))\n",
    "    else:\n",
    "        X=np.zeros(N)\n",
    "        for j in range(N):\n",
    "            X[j]=random.choice(Xr)\n",
    "    test_dataFlv[i,]=np.log(X)\n",
    "    test_dataFv[i,:len(Xr)]=Xr\n",
    "    test_labelsFv[i]=gamma\n",
    "    \n",
    "    \n",
    "## Cauchy\n",
    "test_dataClv=np.zeros((M,N))\n",
    "test_dataCv=np.zeros((M,N+dif))\n",
    "test_labelsCv=np.zeros(M)\n",
    "\n",
    "for i in range(M):\n",
    "    Nr=np.random.randint(N-dif,N+dif)\n",
    "    Xr=np.random.standard_cauchy(size=Nr)\n",
    "    if Nr>=N:\n",
    "        X=np.asarray(random.sample(list(Xr),N))\n",
    "    else:\n",
    "        X=np.zeros(N)\n",
    "        for j in range(N):\n",
    "            X[j]=random.choice(Xr)\n",
    "    test_dataClv[i,]=np.log(abs(X))\n",
    "    test_dataCv[i,:len(Xr)]=Xr\n",
    "    test_labelsCv[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamma_hatFv=np.zeros(500)\n",
    "\n",
    "for i in range(500):\n",
    "    X=test_dataFv[i,][test_dataFv[i,]>0]\n",
    "    k1=K_star(X)\n",
    "    Gamma_hatFv[i]=Hill(X,k1)\n",
    "    \n",
    "    \n",
    "Gamma_hatCv=np.zeros(500)\n",
    "\n",
    "for i in range(500):\n",
    "    X=test_dataCv[i,][test_dataCv[i,]>0]\n",
    "    k1=K_star(X)\n",
    "    Gamma_hatCv[i]=Hill(X,k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_star - Frechet - MSE: 0.00523065245957 , MAE: 0.0558326050504\n",
      "500/500 [==============================] - 0s 60us/step\n",
      "DNN - Frechet - MSE: 0.00190217754804 , MAE: 0.03346574229\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"K_star - Frechet - MSE:\", np.mean(np.power((Gamma_hatFv-test_labelsFv),2)),\", MAE:\", np.mean(np.abs((Gamma_hatFv-test_labelsFv))))\n",
    "EvF=modelH.evaluate(test_dataFlv, test_labelsFv)\n",
    "print(\"DNN - Frechet - MSE:\", EvF[0], \", MAE:\", EvF[1])\n",
    "\n",
    "plt.hist(Gamma_hatFv, bins=20, label=\"K_star\")\n",
    "plt.hist(modelH.predict(test_dataFlv), bins=20, label=\"DNN\")\n",
    "legend = plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_star - Cauchy - MSE: 0.0366999681922 , MAE: 0.14403536628\n",
      "500/500 [==============================] - 0s 71us/step\n",
      "DNN - Cauchy - MSE: 0.0132186456621 , MAE: 0.0965670490861\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEqJJREFUeJzt3XuQnXV9x/H3lyS43BogJJTJSjc4CDihRGcrt4IEhNGAhM5Ax6I0OAyMtlAuAgJRFBocpBdtB1saRKAdkasjAQIUAhmgAsNGLhJSy8UUtlATUwgXsxjg2z/2wARyNufZ3bPn7P72/Zphds85z7Pnk8PZT375nef5PZGZSJLGvs3aHUCS1BwWuiQVwkKXpEJY6JJUCAtdkgphoUtSISx0SSqEhS5JhbDQJakQE1v5ZDvssEN2dXW18iklacxbtmzZbzJzaqPtWlroXV1d9PT0tPIpJWnMi4j/rrKdUy6SVAgLXZIKYaFLUiFaOocuSfWsX7+e3t5e+vr62h2lrTo6Oujs7GTSpElD2t9Cl9R2vb29bLPNNnR1dRER7Y7TFpnJmjVr6O3tZcaMGUP6GU65SGq7vr4+pkyZMm7LHCAimDJlyrD+lWKhSxoVxnOZv2u4r4GFLkmFcA5d0qjTdc5tTf15Ky8+vKk/b7Sy0KUxbDjFN15Krqqtt96a119/HYDFixdz6qmnsmTJEnbeeedK+z/22GO8+OKLzJkzZyRjbpJTLpK0gSVLlnDKKadwxx13VC5z6C/0xYsXD+q53nrrrcHG2yRH6JJUc//993PiiSeyePFiPvKRjwy43Q033MAFF1zAhAkTmDx5MnfffTfnn38+69at44EHHuDcc89lxowZnHbaaaxbt44tttiCK6+8kt12242rrrqK2267jb6+Pt544w3uueeepuW30CUJePPNN5k7dy5Lly5l99133+S2F154IXfeeSfTp0/nlVdeYfPNN+fCCy+kp6eHSy+9FIBXX32V++67j4kTJ3L33Xdz3nnncdNNNwHw4IMP8sQTT7D99ts39c/glIskAZMmTWK//fbjiiuuaLjt/vvvz/HHH8/ll1/O22+/XXebtWvXcswxxzBz5kxOP/10li9f/t5jhx56aNPLHCx0SQJgs8024/rrr+eRRx7h29/+9ia3veyyy1iwYAEvvPACs2bNYs2aNRtt841vfIPZs2fz5JNPcsstt7zvhKGtttqq6fnBKRdJo1C7jsDZcsstufXWWznggAPYcccdOeGEE+pu9+yzz7L33nuz9957c8stt/DCCy+wzTbb8Nprr723zdq1a5k+fToAV111VSviO0KXpA1tv/323HHHHSxYsICbb7657jZnnXUWe+65JzNnzuTAAw9kr732Yvbs2Tz11FPMmjWL6667jrPPPptzzz2X/ffff8BpmWaLzGzJEwF0d3enVyySmqeU49BXrFjBHnvs0e4Yo0K91yIilmVmd6N9HaFLUiGcQ5ekAVx00UXccMMN77vvmGOOYf78+W1KtGkWuiQNYP78+aO2vOtxykWSCmGhS1IhLHRJKoRz6JJGn29NbvLPW9twkwkTJrDnnnuyfv16Jk6cyLx58zjttNPYbLPNWLp0KbNnz2bRokV87nOfA+CII47gzDPP5KCDDuKggw7i9ddf593Dsnt6ejjzzDNZunRpc/8cDThClyRgiy224LHHHmP58uXcddddLF68mAsuuOC9xzs7O7nooosG3H/VqlXcfvvtrYg6IAtdkj5g2rRpLFy4kEsvvZR3T77ca6+9mDx5MnfddVfdfc466ywWLFjQypgbsdAlqY5ddtmFd955h1WrVr1339e//vUBS3vfffflQx/6EPfee2+rIm6kUqFHxOkRsTwinoyIH0dER0TMiIiHI+LpiLguIjYf6bCS1EofXBrlgAMOAPovhFHPpgq/FRoWekRMB/4K6M7MmcAE4PPAd4DvZuauwMtA/WXJJGkMeu6555gwYQLTpk173/3z588fcC794IMPpq+vj4ceeqgVETdSdcplIrBFREwEtgReAg4Gbqw9fjVwVPPjSVLrrV69mi9/+cucfPLJRMT7HjvssMN4+eWXefzxx+vuO3/+fC655JJWxNxIw8MWM/N/IuJvgeeBdcC/A8uAVzLz3Suc9gLTRyylpPGlwmGGzbZu3TpmzZr13mGLxx13HGeccUbdbefPn8/cuXPrPjZnzhymTp06klEH1LDQI2I7YC4wA3gFuAH4bJ1N667DGxEnAScBg7qCtiS10qbWLH/3WPN3HXnkke+bX//g8ebLli1rdrxKqky5fBr4VWauzsz1wE+A/YBta1MwAJ3Ai/V2zsyFmdmdmd3t+ltLksaDKmeKPg/sExFb0j/lcgjQA9wLHA1cC8wD6l/aQ9LgDXSmZBumIjR2NByhZ+bD9H/4+XPgF7V9FgJfA86IiGeAKUDjS2VL0gBaefW00Wq4r0GltVwy85vANz9w93PAJ4f17JIEdHR0sGbNGqZMmbLRUSXjRWayZs0aOjo6hvwzXJxLUtt1dnbS29vL6tWr2x2lrTo6Oujs7Bzy/ha6pLabNGkSM2bMaHeMMc+1XCSpEBa6JBXCQpekQljoklQIC12SCmGhS1IhLHRJKoSFLkmFsNAlqRAWuiQVwkKXpEJY6JJUCAtdkgrhaotSOw10ZSJpCByhS1IhLHRJKoRTLtJY8oEpmpW1q5V19V3ThjAabRyhS1IhHKFLBVjZceyAjzl6Hz8coUtSISx0SSqEhS5JhbDQJakQfigqjVNd59w25H1XXnx4E5OoWRyhS1IhLHRJKoSFLkmFsNAlqRAWuiQVwkKXpEJY6JJUCAtdkgphoUtSISx0SSqEhS5JhahU6BGxbUTcGBH/GRErImLfiNg+Iu6KiKdrX7cb6bCSpIFVHaH/A3BHZu4O7AWsAM4BlmTmrsCS2m1JUps0LPSI+D3gQOAKgMz8XWa+AswFrq5tdjVw1EiFlCQ1VmWEvguwGrgyIh6NiB9ExFbAjpn5EkDt67QRzClJaqBKoU8EPgH8c2Z+HHiDQUyvRMRJEdETET2rV68eYkxJUiNVCr0X6M3Mh2u3b6S/4H8dETsB1L6uqrdzZi7MzO7M7J46dWozMkuS6mhY6Jn5v8ALEbFb7a5DgKeARcC82n3zgJtHJKEkqZKql6A7BfhRRGwOPAd8if6/DK6PiBOA54FjRiaiJKmKSoWemY8B3XUeOqS5cSRJQ+WZopJUCAtdkgpRdQ5d0lB9a3K7E2iccIQuSYWw0CWpEBa6JBXCQpekQljoklQIC12SCuFhi9IwdZ1z2yYfX9nRoiAa9xyhS1IhHKFLGrRG/yppZOXFhzcpiTbkCF2SCmGhS1IhLHRJKoSFLkmFsNAlqRAWuiQVwkKXpEJY6JJUCAtdkgphoUtSISx0SSqEhS5JhbDQJakQFrokFcJCl6RCWOiSVAgLXZIK4RWLJLXccK545NWOBuYIXZIKYaFLUiEsdEkqhIUuSYWw0CWpEBa6JBXCwxalwq3sOLbu/V1917Q4iUZa5RF6REyIiEcj4tba7RkR8XBEPB0R10XE5iMXU5LUyGCmXE4FVmxw+zvAdzNzV+Bl4IRmBpMkDU6lQo+ITuBw4Ae12wEcDNxY2+Rq4KiRCChJqqbqCP17wNnAO7XbU4BXMvOt2u1eYHqTs0mSBqFhoUfEEcCqzFy24d11Ns0B9j8pInoiomf16tVDjClJaqTKCH1/4MiIWAlcS/9Uy/eAbSPi3aNkOoEX6+2cmQszszszu6dOndqEyJKkehoWemaem5mdmdkFfB64JzO/ANwLHF3bbB5w84illCQ1NJwTi74GnBERz9A/p35FcyJJkoZiUCcWZeZSYGnt++eATzY/kiRpKDz1X5IKYaFLUiEsdEkqhIUuSYWw0CWpEBa6JBXCQpekQljoklQIC12SCuEl6CSg65zb2h1BGjZH6JJUCAtdkgphoUtSISx0SSqEhS5JhfAoF2mcWtlxbN37u/quaXESNYsjdEkqhIUuSYWw0CWpEBa6JBXCQpekQljoklQIC12SCmGhS1IhLHRJKoRnikoaU4azdv3Kiw9vYpLRxxG6JBXCQpekQljoklQIC12SCmGhS1IhLHRJKoSHLaoYwzmcTSqBI3RJKoSFLkmFsNAlqRAWuiQVomGhR8SHI+LeiFgREcsj4tTa/dtHxF0R8XTt63YjH1eSNJAqI/S3gK9m5h7APsBfRsTHgHOAJZm5K7CkdluS1CYNCz0zX8rMn9e+fw1YAUwH5gJX1za7GjhqpEJKkhob1Bx6RHQBHwceBnbMzJegv/SBac0OJ0mqrvKJRRGxNXATcFpmvhoRVfc7CTgJYOeddx5KRmlMWNlxbLsjaJyrNEKPiEn0l/mPMvMntbt/HRE71R7fCVhVb9/MXJiZ3ZnZPXXq1GZkliTVUeUolwCuAFZk5t9v8NAiYF7t+3nAzc2PJ0mqqsqUy/7AccAvIuKx2n3nARcD10fECcDzwDEjE1GSVEXDQs/MB4CBJswPaW4cSdJQeaaoJBXCQpekQljoklQIC12SCmGhS1IhLHRJKoTXFJUG4Kn8GmscoUtSISx0SSqEUy4aVbrOua3dEaQxyxG6JBXCQpekQljoklQIC12SCmGhS1IhPMpF0vsMdEJVV981LU6iwXKELkmFsNAlqRBOuUgaN4Zz4trKiw9vYpKR4QhdkgphoUtSISx0SSqEhS5JhbDQJakQFrokFcLDFtV0rmkutYcjdEkqhIUuSYWw0CWpEM6hS6pkoFUYwZUYRwtH6JJUCAtdkgrhlMsoVvrKcKPFpqYSpLHEEbokFcIRujbiiUFqFi9n11qO0CWpEGNmhO588uCM11G2I8L2GOznEGPx/9NY6KBhjdAj4jMR8cuIeCYizmlWKEnS4A15hB4RE4DvA4cCvcAjEbEoM59qVrgSjNeRcrM0ayTnkSwaD4YzQv8k8ExmPpeZvwOuBeY2J5YkabCGU+jTgRc2uN1bu0+S1AbD+VA06tyXG20UcRJwUu3m6xHxy2E855DEd4a02w7Ab5qbpGXGavaNctd7k/U7ou69A28/osbq6w2jLnv9/691jLLcm7ZBBw019x9U2Wg4hd4LfHiD253Aix/cKDMXAguH8TxtERE9mdnd7hxDMVazm7v1xmp2c9c3nCmXR4BdI2JGRGwOfB5Y1JxYkqTBGvIIPTPfioiTgTuBCcAPM3N505JJkgZlWCcWZeZiYHGTsow2Y26aaANjNbu5W2+sZjd3HZG50eeYkqQxyLVcJKkQ477QGy1fEBFnRMRTEfFERCyJiEqHD420qssuRMTREZERMWqOCKiSPSL+tPa6L4+IUbHAR4X3ys4RcW9EPFp7v8xpR84PiogfRsSqiHhygMcjIv6x9ud6IiI+0eqM9VTI/YVa3ici4mcRsVerM9bTKPcG2/1RRLwdEUc37ckzc9z+R/+Huc8CuwCbA48DH/vANrOBLWvffwW4bizkrm23DXAf8BDQ3e7cg3jNdwUeBbar3Z42RnIvBL5S+/5jwMp2565lORD4BPDkAI/PAW6n/zD+fYCH2525Yu79NniPfHas5N7g/XQP/Z9BHt2s5x7vI/SGyxdk5r2Z+dvazYfoP96+3aouu/DXwCVAXyvDNVAl+4nA9zPzZYDMXNXijPVUyZ3A79W+n0yd8zLaITPvA/5vE5vMBf41+z0EbBsRO7Um3cAa5c7Mn737HmH0/G5Web0BTgFuApr63h7vhT7Y5QtOoH8k024Nc0fEx4EPZ+atrQxWQZXX/KPARyPiPyLioYj4TMvSDaxK7m8BX4yIXvpHXqe0JtqwlbCMx2j53WwoIqYDfwJc1uyfPWbWQx8hlZYvAIiILwLdwKdGNFE1m8wdEZsB3wWOb1WgQajymk+kf9rlIPpHXfdHxMzMfGWEs21Kldx/BlyVmX8XEfsC/1bL/c7IxxuWyr8Ho1FEzKa/0P+43Vkq+h7wtcx8O6K5i1WM90KvtHxBRHwamA98KjPfbFG2TWmUextgJrC09ob5fWBRRByZmT0tS1lflde8F3goM9cDv6qt/7Mr/Wcnt0uV3CcAnwHIzAcjooP+tTtGw5TRplT6PRiNIuIPgR8An83MNe3OU1E3cG3td3MHYE5EvJWZPx3uDx7vUy4Nly+oTV38C3DkKJnLhQa5M3NtZu6QmV2Z2UX//OJoKHOotmTET+n/MJqI2IH+KZjnWppyY1VyPw8cAhARewAdwOqWphyaRcCf14522QdYm5kvtTtUIxGxM/AT4LjM/K9256kqM2ds8Lt5I/AXzShzGOcj9Bxg+YKIuBDoycxFwN8AWwM31P5GfT4zj2xbaCrnHpUqZr8TOCwingLeBs5q9+irYu6vApdHxOn0T1kcn7VDGtopIn5M//TVDrX5/W8CkwAy8zL65/vnAM8AvwW+1J6k71ch9/nAFOCfar+bb+UoWLCrQu6Re+5R8H6TJDXBeJ9ykaRiWOiSVAgLXZIKYaFLUiEsdEkqhIUuSYWw0CWpEBa6JBXi/wHnGMoy2gLBGgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"K_star - Cauchy - MSE:\", np.mean(np.power((Gamma_hatCv-test_labelsCv),2)),\", MAE:\", np.mean(np.abs((Gamma_hatCv-test_labelsCv))))\n",
    "EvC=modelH.evaluate(test_dataClv, test_labelsCv)\n",
    "print(\"DNN - Cauchy - MSE:\", EvC[0], \", MAE:\", EvC[1])\n",
    "\n",
    "plt.hist(Gamma_hatCv, bins=20, label=\"K_star\")\n",
    "plt.hist(modelH.predict(test_dataClv), bins=20, label=\"DNN\")\n",
    "legend = plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly the DNN does not suffer much from the resampling scheme and still peforms better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Training neural networks in order to learn the extreme value index without the necessary selection of a threshold or sample fraction seems worth further investigation. It would be very interesenting to get insight on the structure of the network and understand how it larns to estimate this parameter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
